{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multi-layer Perceptron\n",
    "\n",
    "Use a Multilayer Perceptron (MLP) network to classify hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('pendigits_train.csv')\n",
    "test = pd.read_csv('pendigits_test.csv')\n",
    "def split_x_y_array(df,ylabel):\n",
    "    \"\"\"Split data based on last column and change them into arrays\"\"\"\n",
    "    y = np.asarray(df[ylabel])\n",
    "    x = np.asarray(df.drop(ylabel,1))\n",
    "    return x,y\n",
    "train_x, train_y = split_x_y_array(train,'y')\n",
    "test_x, test_y = split_x_y_array(test,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sknn\n",
    "from sknn.mlp import Classifier, Layer\n",
    "def Perceptron(classifier, no_unit, iterations):\n",
    "    nn = classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=no_unit),\n",
    "        Layer(\"Sigmoid\")],\n",
    "    learning_rate=0.01,\n",
    "    n_iter=iterations)\n",
    "    return nn\n",
    "nn_list = []\n",
    "unit_list = [10,20]\n",
    "iter_list = [50, 100]\n",
    "for i in unit_list:\n",
    "    for j in iter_list:\n",
    "        nn_list.append(Perceptron(Classifier, i, j)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_fit = []\n",
    "for classifier in nn_list:\n",
    "    nn_fit.append(classifier.fit(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61623018256595086, 0.68636585184193921, 0.96919613177793884, 0.97976354854017189]\n"
     ]
    }
   ],
   "source": [
    "#Analyze performance changes, f1 score and confusion matrix\n",
    "f1scores = []\n",
    "pred_list = []\n",
    "for eachfit in nn_fit:\n",
    "    predict = eachfit.predict(test_x)\n",
    "    pred_list.append(predict)\n",
    "for predict in pred_list:\n",
    "    f1 = metrics.f1_score(test_y,predict, average = 'weighted')\n",
    "    f1scores.append(f1)\n",
    "print f1scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for j in range(len(pred_list)):\n",
    "    new = pd.Series(sum(pred_list[j].tolist(),[]))\n",
    "    y_pred.append(new)\n",
    "y_true = pd.Series(list(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>292</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>604</td>\n",
       "      <td>180</td>\n",
       "      <td>580</td>\n",
       "      <td>44</td>\n",
       "      <td>291</td>\n",
       "      <td>2</td>\n",
       "      <td>296</td>\n",
       "      <td>167</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2   3    4  5    6    7  8   9   All\n",
       "True                                                       \n",
       "0          295    0    0   0    1  0    0    6  0   0   302\n",
       "1            0  155   22  32    4  0    0    0  0   0   213\n",
       "2            0   17  292  11    0  0    0    3  0   0   323\n",
       "3            0    1  264   0    0  1    0    2  0   0   268\n",
       "4            0    0    0   0  278  0    0    0  0   0   278\n",
       "5          126    0    1   1    0  1    0    0  0   0   129\n",
       "6            0    0    0   0    0  0  296    0  0   0   296\n",
       "7            0    7    1   0    8  0    0  156  0   0   172\n",
       "8          182    0    0   0    0  0    0    0  8   0   190\n",
       "9            1    0    0   0    0  0    0    0  0  55    56\n",
       "All        604  180  580  44  291  2  296  167  8  55  2227"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix for unit = 10, n_iter = 50\n",
    "pd.crosstab(y_true, y_pred[0], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>528</td>\n",
       "      <td>223</td>\n",
       "      <td>599</td>\n",
       "      <td>274</td>\n",
       "      <td>14</td>\n",
       "      <td>296</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    4   5    6    7   8   9   All\n",
       "True                                                     \n",
       "0          299    0    0    2   0    0    1   0   0   302\n",
       "1            0  202   10    0   0    0    1   0   0   213\n",
       "2            0    7  315    0   0    0    1   0   0   323\n",
       "3            0    1  266    0   0    0    1   0   0   268\n",
       "4            0    1    0  271   0    0    4   0   2   278\n",
       "5          126    0    3    0   0    0    0   0   0   129\n",
       "6            0    0    0    0   0  296    0   0   0   296\n",
       "7            0   12    5    1   0    0  154   0   0   172\n",
       "8          103    0    0    0   0    0    0  87   0   190\n",
       "9            0    0    0    0  14    0    0   1  41    56\n",
       "All        528  223  599  274  14  296  162  88  43  2227"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix for unit = 10, n_iter = 100\n",
    "pd.crosstab(y_true, y_pred[1], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>304</td>\n",
       "      <td>226</td>\n",
       "      <td>326</td>\n",
       "      <td>269</td>\n",
       "      <td>275</td>\n",
       "      <td>127</td>\n",
       "      <td>295</td>\n",
       "      <td>158</td>\n",
       "      <td>188</td>\n",
       "      <td>59</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8   9   All\n",
       "True                                                            \n",
       "0          301    0    0    0    0    0    0    0    1   0   302\n",
       "1            0  194   18    0    0    0    0    1    0   0   213\n",
       "2            0   14  307    0    0    0    0    2    0   0   323\n",
       "3            0    1    0  266    1    0    0    0    0   0   268\n",
       "4            0    0    1    0  273    0    0    0    0   4   278\n",
       "5            0    0    0    3    0  126    0    0    0   0   129\n",
       "6            0    0    0    0    0    1  295    0    0   0   296\n",
       "7            0   17    0    0    1    0    0  154    0   0   172\n",
       "8            3    0    0    0    0    0    0    0  187   0   190\n",
       "9            0    0    0    0    0    0    0    1    0  55    56\n",
       "All        304  226  326  269  275  127  295  158  188  59  2227"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix for unit = 20, n_iter = 50\n",
    "pd.crosstab(y_true, y_pred[2], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>301</td>\n",
       "      <td>214</td>\n",
       "      <td>335</td>\n",
       "      <td>269</td>\n",
       "      <td>278</td>\n",
       "      <td>132</td>\n",
       "      <td>296</td>\n",
       "      <td>158</td>\n",
       "      <td>187</td>\n",
       "      <td>57</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8   9   All\n",
       "True                                                            \n",
       "0          301    0    0    0    0    0    0    0    1   0   302\n",
       "1            0  197   15    0    1    0    0    0    0   0   213\n",
       "2            0    3  320    0    0    0    0    0    0   0   323\n",
       "3            0    1    0  267    0    0    0    0    0   0   268\n",
       "4            0    0    0    0  276    0    0    0    0   2   278\n",
       "5            0    0    0    2    0  127    0    0    0   0   129\n",
       "6            0    0    0    0    0    0  296    0    0   0   296\n",
       "7            0   13    0    0    1    0    0  158    0   0   172\n",
       "8            0    0    0    0    0    5    0    0  185   0   190\n",
       "9            0    0    0    0    0    0    0    0    1  55    56\n",
       "All        301  214  335  269  278  132  296  158  187  57  2227"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix for unit = 20, n_iter = 100\n",
    "pd.crosstab(y_true, y_pred[3], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n",
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "units = [10,20,30,40,50,60,70,80,90,100]\n",
    "pred_new = []\n",
    "for i in units:\n",
    "        pred_new.append(Perceptron(Classifier, i, 10).fit(train_x,train_y).predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGFZJREFUeJzt3X2QHPV95/H3h5XEkwEhCYGeQBIIIgjYAvRAbMfjwMUb\nV2ISX6qEUnEezuejLseZc9XFilyp8lZdnS/UXeqcK5IUZ2Mu5aqYq4OLI8c+MM55uJCweogekEAL\nkpGMFsmICAmEhCXt7vf+6BYajXZnZndnpnt6Pq+qqZnu6en+arT6bOv769+MIgIzMyueC7IuwMzM\nWsMBb2ZWUA54M7OCcsCbmRWUA97MrKAc8GZmBVU34CV9Q9IbknbU2Oa/SdotabukZc0t0czMJqKR\nM/jHgN6xnpT0SeCGiFgC/Cvgz5tUm5mZTULdgI+IvwOO1NjkU8BfpNtuAKZLuro55ZmZ2UQ1owc/\nD9hfsTwIzG/Cfs3MbBKaNciqqmV//oGZWcamNGEfrwMLKpbnp+vOIcmhb2Y2ARFRfRLdkGacwa8H\nfgtA0irgaES8MdqGEZGr25e//OXMa+iEmvJal2tyTd1Q12TUPYOX9C3gY8AsSfuBLwNT08B+JCK+\nJ+mTkvYAx4HfnVRFZmbWFHUDPiLWNLDNA80px8zMmqWrZ7KWSqWsSzhPHmuCfNblmhrjmhqX17om\nSpPt8TR8ICnadSwzs6KQRExwkLUZV9GYmeXeyAgcPgwHD8JPfnL+7dChZBsJLrhg/PcTeU0j+5wM\nB7yZdbR33x09sKuD/M034fLLYc4cuOaas7d58+DOO+Gqq6CnJwn5iIndT+a1Y91Phls0ZpY7Q0PJ\nGfVYYV15Gx4+P7TP3CrXz54N06Zl/Scbv8m0aBzwZtY2w8MwOAh7944e2mfWHTkCM2eOHtzV6y67\nLGlpFJUD3sxyY3gYXnsN9uyB3buT+zO3vXthxgxYvBjmzh07uGfNgiluIAMOeDNrs6Eh+PGPzw/w\n3buT9bNnww03nL0tWZLcL14Ml16adfWdxQFvZk13+nRyxl0d4Hv2JGfoc+acG95nbosXw8UXZ119\ncTjgzWxCTp48N8Qrz8gHB5MrTKoDfMkSWLQILrww6+q7gwPezMb005/Cq6+O3hM/cACuvXb0dsrC\nhZ151UnROODNcmJ4GE6dSs6MT54893H18mS3a/Q1p08nYV0d4DfcANddB1OnZv2uWS0OeLMmGBmB\nY8fg6FF4++3x3Z95fPJk0ro4c5s2bezlsR43ul2jr7nkkmQCj3UmB7wZSbiOFbyN3B87llzhccUV\nMH16cjvzuJH7K65IBheLfE22tZ8D3loqIvlv/nhup06N/zXj3dexY+eG9PDw2AHcSEhffrnPdC1/\nHPBdZmgI3nuvNbcTJ85fd/JkMulk6tTx36ZNm9jrGtnXZZedG9I+e7YicsB3uIMHYcMG2LgRXnwR\njh+vHcIjI0mYtet20UWT/1Q7M5sYB3wHefdd2Lw5CfMzoX7iBKxYAStXwm23JWemtQJ36lSfqZp1\nCwd8Tg0Nwc6d54b5q68mIb5y5dlQX7zYgW1mo3PA50BE8hkcGzeeDfStW2HBgrNhvmJFEu6ePGJm\njXLAZ+DIEdi06dyz8wsuODfMly9PBv/MzCbKAd9iJ0/C9u3nhvmBA3D77ee2WubPd6vFzJrLAd9E\nEcnndVSG+Y4dyfTuyjBfutSfV21mrdfSgJfUC3wV6AG+HhEPVT1/JfANYDHwU+BfRMSLo+wnlwF/\n6NC5Yb5pU3IVS2Wr5Y47/BnWZpaNlgW8pB7gZeAe4HVgE7AmInZVbPOfgXci4j9Iugn404i4Z5R9\n5SrgN26E1auTXvry5ecG+jXXZF2dmVliMgFfr8mwAtgTEfvSAz0O3AvsqthmKfBHABHxsqSFkq6K\niDcnUlC7PPFEEvBf+Yon8ZhZMdWLtnnA/orlwXRdpe3ApwEkrQCuA+Y3q8BW6e+Hu+92uJtZcdU7\ng2+kp/JHwJ9I2grsALYCw6Nt2NfX9/7jUqlEqVRqqMhmO30atmxJ2jFmZnlSLpcpl8tN2Ve9Hvwq\noC8ietPldcBI9UBr1Wv2ArdGxLtV63PTg9+yBT7zmeRzX8zM8mwyPfh6DYrNwJK0rz4NWA2srzr4\nFelzSPoc8Gx1uOdNfz+sWpV1FWZmrVWzRRMRQ5IeAJ4muUzy0YjYJen+9PlHgJuB/yEpgJ3AZ1tc\n86T198NHP5p1FWZmrdWVE51uvBGefBJuvTXrSszMavNM1nE4fBgWLUquf/e395hZ3rWyB184GzYk\nE5sc7mZWdF0X8P39cNddWVdhZtZ6XRfwzz/vK2jMrDt0VQ9+eBhmzIA9e+CqqzItxcysIe7BN2hg\nIAl2h7uZdYOuCnhPcDKzbuKANzMrKAe8mVlBdc0g6zvvwJw5yQSnadMyK8PMbFw8yNqATZtg2TKH\nu5l1j64JeLdnzKzbdFXAewarmXWTrujBR8Ds2bBtG8yr/sJBM7Mccw++jh/9CC66yOFuZt2lKwLe\n/Xcz60YOeDOzgnLAm5kVVOEHWU+cgFmzkm9yuvjith/ezGxSPMhaw5YtcMstDncz6z6FD3i3Z8ys\nW3VFwHuCk5l1o64IeJ/Bm1k3qhvwknolDUjaLWntKM/PkvSUpG2Sdkr6nZZUOgH798OpU7BoUdaV\nmJm1X82Al9QDPAz0AjcDayQtrdrsAWBrRHwIKAF/LGlKC2odtzNn75rQ+LOZWWerdwa/AtgTEfsi\n4jTwOHBv1TYHgcvTx5cDhyNiqLllTozbM2bWzeoF/Dxgf8XyYLqu0teAWyQdALYDDzavvMlxwJtZ\nN6vXSmlkZtKXgG0RUZJ0PfCMpA9GxLHqDfv6+t5/XCqVKJVK4yh1fE6dSj49cvnylh3CzKzpyuUy\n5XK5KfuqOZNV0iqgLyJ60+V1wEhEPFSxzfeA/xgRf58u/y2wNiI2V+2rrTNZN22Cz34WXnihbYc0\nM2u6Vs5k3QwskbRQ0jRgNbC+apsB4J60kKuBm4BXJ1JMM7k9Y2bdrmaLJiKGJD0APA30AI9GxC5J\n96fPPwJ8BXhM0naSXxhfjIi3Wlx3Xf39cPfdWVdhZpadwn7Y2PXXw9/8DSytvqjTzKyD+MPGqhw6\nlHx65E03ZV2JmVl2Chnw/f2wciVcUMg/nZlZYwoZgR5gNTNzwJuZFVbhBlmHh2H6dNi3D2bObPnh\nzMxayoOsFV58EebOdbibmRUu4N2eMTNLOODNzAqqkAHvr+gzMyvYIOvRo7BgARw5AlNy8ZUjZmaT\n40HW1IYNcMcdDnczMyhYwLv/bmZ2lgPezKygCtODHxmBWbOS6+DnzGnZYczM2so9eGD3brj8coe7\nmdkZhQl4t2fMzM7lgDczKygHvJlZQRVikPX4cZg9G956Cy68sCWHMDPLRNcPsm7eDLfd5nA3M6tU\niIB//nm3Z8zMqhUi4N1/NzM7X8cHfIQD3sxsNHUDXlKvpAFJuyWtHeX5fy9pa3rbIWlI0vTWlHu+\nH/8YJLj22nYd0cysM9QMeEk9wMNAL3AzsEbS0sptIuK/RMSyiFgGrAPKEXG0VQVXO3P2rgmNMZuZ\nFVe9M/gVwJ6I2BcRp4HHgXtrbP8bwLeaVVwj3J4xMxtdvYCfB+yvWB5M151H0iXAJ4Anm1NaYxzw\nZmajq/fVGOOZmfQrwHO12jN9fX3vPy6VSpRKpXHs/nwnT8KOHXDnnZPajZlZbpTLZcrlclP2VXMm\nq6RVQF9E9KbL64CRiHholG3/CvifEfH4GPtq+kzW/n74vd+DLVuaulszs9xo5UzWzcASSQslTQNW\nA+tHKeAK4OeBv55IERPl9oyZ2dhqBnxEDAEPAE8DL5Gcoe+SdL+k+ys2/VXg6Yh4r3Wlns8zWM3M\nxtbRHzZ23XXwzDNw441N3a2ZWW505YeNHTgA774LS5ZkXYmZWT51bMBv2AArV3qCk5nZWDo24D3A\namZWmwPezKygOnKQdWgIpk+HwcHk3sysqLpukHXHjuQKGoe7mdnYOjLg3Z4xM6vPAW9mVlAdGfCe\nwWpmVl/HDbIePgyLFsGRI9DT04TCzMxyrKsGWTdsgOXLHe5mZvV0XMC7/25m1hgHvJlZQXVUD35k\nBGbMgFdegdmzm1SYmVmOdU0PfmAAZs1yuJuZNaKjAt7tGTOzxjngzcwKygFvZlZQHTPI+s47MHcu\nvPUWTJvWxMLMzHKsKwZZN22CD33I4W5m1qiOCXi3Z8zMxscBb2ZWUB3Rg49Irn3fuhXmz29yYWZm\nOdbSHrykXkkDknZLWjvGNiVJWyXtlFSeSCG1vPoqXHihw93MbDym1HpSUg/wMHAP8DqwSdL6iNhV\nsc104E+BT0TEoKRZzS6yvx/uuqvZezUzK7Z6Z/ArgD0RsS8iTgOPA/dWbfMbwJMRMQgQEf/U7CLd\nfzczG796AT8P2F+xPJiuq7QEmCHph5I2S/pMMwsEB7yZ2UTUbNEAjYyKTgVuB+4GLgGel9QfEbur\nN+zr63v/calUolQq1d35e+/BSy/B7bc3UImZWYcrl8uUy+Wm7KvmVTSSVgF9EdGbLq8DRiLioYpt\n1gIXR0Rfuvx14KmIeKJqXxO6iua55+ALX0gmOpmZdZtWXkWzGVgiaaGkacBqYH3VNn8NfERSj6RL\ngJXASxMpZjRuz5iZTUzNFk1EDEl6AHga6AEejYhdku5Pn38kIgYkPQW8AIwAX4uIpgb8r/1as/Zm\nZtY9cj/Raf58ePZZuP76FhRlZpZzhf2wscFBOHkSFi/OuhIzs86T64A/M8FJE/rdZWbW3XIf8B5g\nNTObGAe8mVlB5XaQ9dQpmDEDDh6Eyy5rYWFmZjlWyEHW7duTwVWHu5nZxOQ24N2eMTObHAe8mVlB\nOeDNzAoqlwF/6BAcPgw/8zNZV2Jm1rlyGfAbNsCKFXBBLqszM+sMuYxQf0Wfmdnk5Tbg3X83M5uc\n3E10Gh6GK6+EvXth5sw2FGZmlmOFmuj00kswZ47D3cxssnIX8M8/7/aMmVkz5C7g3X83M2sOB7yZ\nWUHlapD16NHkK/qOHoUpNb8t1sysOxRmkHXjRrjjDoe7mVkz5CrgPcHJzKx5chfw7r+bmTVHbnrw\nETBrFuzcmVwHb2ZmLe7BS+qVNCBpt6S1ozxfkvS2pK3p7Q8nUsju3cm3Nznczcyao+ZwpqQe4GHg\nHuB1YJOk9RGxq2rTZyPiU5MpxO0ZM7PmqncGvwLYExH7IuI08Dhw7yjbTei/D5U8g9XMrLnqBfw8\nYH/F8mC6rlIAPydpu6TvSbp5IoX4DN7MrLnqXXHeyAjsFmBBRJyQ9EvAt4EbR9uwr6/v/celUolS\nqQTA8ePw8suwbFkDRzMzK7ByuUy5XG7KvmpeRSNpFdAXEb3p8jpgJCIeqvGavcAdEfFW1foxr6J5\n9llYuzY5izczs7NaeRXNZmCJpIWSpgGrgfVVB79aktLHK0h+abx1/q7G5vaMmVnz1WzRRMSQpAeA\np4Ee4NGI2CXp/vT5R4BfB/61pCHgBHDfeIvo74f7xv0qMzOrJfOJThEwd24S8tdd15ZSzMw6Rkd/\n2NhrryX3116bbR1mZkWTecCf6b9r0lfSm5lZpdwEvJmZNVfmAe8ZrGZmrZHpIOvJk3DllfDmm3Dp\npW0pw8yso3TsIOvWrXDTTQ53M7NWyDTg3X83M2sdB7yZWUFlHvD+DlYzs9bILOAPHoRjx2DJkqwq\nMDMrtswCfsMGWLnSE5zMzFols4B3/93MrLUc8GZmBZXJRKehoWSC0/79MH16Ww5vZtaROm6i044d\nsGCBw93MrJUyCXi3Z8zMWs8Bb2ZWUJkFvCc4mZm1VtsHWQ8fhkWL4MgR6Olpy6HNzDpWRw2ybtwI\ny5c73M3MWq3tAe/+u5lZezjgzcwKqq09+OHhYMYMeOUVmD27LYc1M+toLe3BS+qVNCBpt6S1NbZb\nLmlI0qfH2mZgAGbOdLibmbVDzYCX1AM8DPQCNwNrJC0dY7uHgKeAMX/TuD1jZtY+9c7gVwB7ImJf\nRJwGHgfuHWW7fws8AbxZa2cOeDOz9qkX8POA/RXLg+m690maRxL6f56uGrOp74A3M2ufKXWeb2QE\n9qvAH0RESBI1WjQDA32sXw/f/S6USiVKpdI4SjUzK75yuUy5XG7KvmpeRSNpFdAXEb3p8jpgJCIe\nqtjmVc6G+izgBPC5iFhfta/48IeD555rSt1mZl1hMlfR1DuD3wwskbQQOACsBtZUbhARiysKeQz4\nTnW4n+H2jJlZ+9QM+IgYkvQA8DTQAzwaEbsk3Z8+/8h4DuaANzNrn7ZOdNq/P5g/vy2HMzMrhMm0\naDL5yj4zM2tMR32apJmZtYcD3sysoBzwZmYF5YA3MysoB7yZWUE54M3MCsoBb2ZWUA54M7OCcsCb\nmRWUA97MrKAc8GZmBeWANzMrKAe8mVlBOeDNzArKAW9mVlAOeDOzgnLAm5kVlAPezKygHPBmZgXl\ngDczKygHvJlZQdUNeEm9kgYk7Za0dpTn75W0XdJWSf8o6RdaU6qZmY1HzYCX1AM8DPQCNwNrJC2t\n2uwHEfHBiFgG/A7w31tRaCuUy+WsSzhPHmuCfNblmhrjmhqX17omqt4Z/ApgT0Tsi4jTwOPAvZUb\nRMTxisUPAP/U3BJbJ49/mXmsCfJZl2tqjGtqXF7rmqh6AT8P2F+xPJiuO4ekX5W0C/g/wOebV56Z\nmU1UvYCPRnYSEd+OiKXArwDfnHRVZmY2aYoYO8MlrQL6IqI3XV4HjETEQzVe8yNgRUQcrlrf0C8L\nMzM7V0RoIq+bUuf5zcASSQuBA8BqYE3lBpKuB16NiJB0e1rM4ar9TLhAMzObmJoBHxFDkh4AngZ6\ngEcjYpek+9PnHwH+OfBbkk4D7wL3tbhmMzNrQM0WjZmZda6WzGSV9A1Jb0jaUbFuhqRnJL0i6fuS\nprfi2DVqWiDph5JelLRT0uezrkvSRZI2SNom6SVJ/ynrmipq60knr30nDzVJ2ifphbSmjTmpabqk\nJyTtSv/+VuagppvS9+jM7W1Jn89BXevSf3s7JP2lpAtzUNODaT07JT2YrmtrTePNyvR93J1OPv3F\nevtv1UcVPEYyOarSHwDPRMSNwN+my+10GvhCRNwCrAL+TTppK7O6IuKnwMcj4kPAbcDHJX0ky5oq\nPAi8xNkrqbKuKYBSRCyLiBU5qelPgO+lV5DdBgxkXVNEvJy+R8uAO4ATwF9lWVc6hvc54PaIuJWk\n3XtfxjX9LPAvgeXAB4FfTscT211Tw1kp6WaScdCb09f8maTaGR4RLbkBC4EdFcsDwNXp42uAgVYd\nu8H6vg3ck5e6gEuATcAtWdcEzAd+AHwc+E4e/v6AvcDMqnWZ1QRcQXJxQfX6XPw8pcf/ReDvsq4L\nmAG8DFxJMu73HeCfZVzTrwNfr1j+Q+CLWdTUaFYC64C1Fds9Bayqte92ftjY1RHxRvr4DeDqNh77\nHOkZxTJgAxnXJekCSdvSY/8wIl7MuibgvwK/D4xUrMu6pgB+IGmzpM/loKZFwJuSHpO0RdLXJF2a\ncU3V7gO+lT7OrK6IeAv4Y+A1kqvxjkbEM1nWBOwEPpq2Qy4BPklyYpOHv7+xaphLMtn0jFEnnlbK\n5NMkI/n1k8norqQPAE8CD0bEsazrioiRSFo084Gfl/TxLGuS9MvAoYjYCox6aWtGf38fjqTt8Esk\n7bWPZlzTFOB24M8i4nbgOFX/nc/453waycTD/1X9XAY/U9cD/47kTHUu8AFJv5llTRExADwEfJ9k\nBv42YDjLmkbTQA0162tnwL8h6RoASXOAQ208Nulxp5KE+zcj4tt5qQsgIt4GvkvSN82ypp8DPiVp\nL8nZ3y9I+mbGNRERB9P7N0l6yisyrmkQGIyITenyEySB/5M8/DyR/CL8x/T9gmzfqzuBf4iIwxEx\nBPxv4C4yfq8i4hsRcWdEfAw4ArxCPvJgrBpeBxZUbDc/XTemdgb8euC308e/TdIDbxtJAh4FXoqI\nr+ahLkmzzoyQS7qYpC+5NcuaIuJLEbEgIhaR/Bf//0bEZ7KsSdIlki5LH19K0lvekWVNEfETYL+k\nG9NV9wAvkvSXM/s5r7CGs+0ZyPbf3wCwStLF6b/De0gG8DN9ryTNTu+vBT4N/CUZ51RqrBrWA/dJ\nmiZpEbAE2FhzTy0aNPgWSa/tFMmHlf0uyUDLD0h+S34fmN7qwYuqmj5C0lPeRhKiW0lGojOrC7gV\n2JLW9ALw++n6TN+rivo+BqzPuiaSfve29LYTWJd1TenxP0gyML6d5Kz0iqxrSuu6lORTXS+rWJf1\ne/VFkl+AO4C/AKbmoKb/l9a0jeRqtra/T+PNSuBLwB6SX5qfqLd/T3QyMysof2WfmVlBOeDNzArK\nAW9mVlAOeDOzgnLAm5kVlAPezKygHPBmZgXlgDczK6j/D4XL+YBxg1JRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dee1690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_new = []\n",
    "for predict in pred_new:\n",
    "    f1 = metrics.f1_score(test_y,predict, average = 'weighted')\n",
    "    f1_new.append(f1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(units, f1_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.98      0.65       302\n",
      "          1       0.86      0.73      0.79       213\n",
      "          2       0.50      0.90      0.65       323\n",
      "          3       0.00      0.00      0.00       268\n",
      "          4       0.96      1.00      0.98       278\n",
      "          5       0.50      0.01      0.02       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       0.93      0.91      0.92       172\n",
      "          8       1.00      0.04      0.08       190\n",
      "          9       1.00      0.98      0.99        56\n",
      "\n",
      "avg / total       0.69      0.69      0.62      2227\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.99      0.72       302\n",
      "          1       0.91      0.95      0.93       213\n",
      "          2       0.53      0.98      0.68       323\n",
      "          3       0.00      0.00      0.00       268\n",
      "          4       0.99      0.97      0.98       278\n",
      "          5       0.00      0.00      0.00       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       0.95      0.90      0.92       172\n",
      "          8       0.99      0.46      0.63       190\n",
      "          9       0.95      0.73      0.83        56\n",
      "\n",
      "avg / total       0.68      0.75      0.69      2227\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       302\n",
      "          1       0.86      0.91      0.88       213\n",
      "          2       0.94      0.95      0.95       323\n",
      "          3       0.99      0.99      0.99       268\n",
      "          4       0.99      0.98      0.99       278\n",
      "          5       0.99      0.98      0.98       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       0.97      0.90      0.93       172\n",
      "          8       0.99      0.98      0.99       190\n",
      "          9       0.93      0.98      0.96        56\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2227\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       302\n",
      "          1       0.92      0.92      0.92       213\n",
      "          2       0.96      0.99      0.97       323\n",
      "          3       0.99      1.00      0.99       268\n",
      "          4       0.99      0.99      0.99       278\n",
      "          5       0.96      0.98      0.97       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       1.00      0.92      0.96       172\n",
      "          8       0.99      0.97      0.98       190\n",
      "          9       0.96      0.98      0.97        56\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivianchu/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(test_y, pred_list[0])\n",
    "print metrics.classification_report(test_y, pred_list[1])\n",
    "print metrics.classification_report(test_y, pred_list[2])\n",
    "print metrics.classification_report(test_y, pred_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       302\n",
      "          1       0.93      0.94      0.94       213\n",
      "          2       0.97      1.00      0.98       323\n",
      "          3       0.99      1.00      0.99       268\n",
      "          4       1.00      1.00      1.00       278\n",
      "          5       1.00      0.98      0.99       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       1.00      0.92      0.96       172\n",
      "          8       0.99      0.99      0.99       190\n",
      "          9       1.00      0.98      0.99        56\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_test = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=100),\n",
    "        Layer(\"Sigmoid\")],\n",
    "    learning_rate=0.01,\n",
    "    n_iter=50)\n",
    "pred_test = nn_test.fit(train_x, train_y).predict(test_x)\n",
    "print metrics.classification_report(test_y,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00       302\n",
      "          1       0.91      0.92      0.92       213\n",
      "          2       0.96      0.99      0.97       323\n",
      "          3       0.98      0.97      0.98       268\n",
      "          4       1.00      1.00      1.00       278\n",
      "          5       0.98      0.98      0.98       129\n",
      "          6       1.00      0.99      0.99       296\n",
      "          7       0.99      0.92      0.95       172\n",
      "          8       0.97      1.00      0.99       190\n",
      "          9       0.98      0.98      0.98        56\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_test = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=50),\n",
    "        Layer(\"Sigmoid\")],\n",
    "    learning_rate=0.01,\n",
    "    n_iter=50)\n",
    "pred_test = nn_test.fit(train_x, train_y).predict(test_x)\n",
    "print metrics.classification_report(test_y,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       302\n",
      "          1       0.92      0.86      0.89       213\n",
      "          2       0.92      0.99      0.95       323\n",
      "          3       1.00      1.00      1.00       268\n",
      "          4       1.00      1.00      1.00       278\n",
      "          5       1.00      0.99      1.00       129\n",
      "          6       1.00      1.00      1.00       296\n",
      "          7       0.99      0.94      0.96       172\n",
      "          8       0.99      1.00      0.99       190\n",
      "          9       0.98      0.98      0.98        56\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_test = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=60),\n",
    "        Layer(\"Sigmoid\")],\n",
    "    learning_rate=0.01,\n",
    "    n_iter=50)\n",
    "pred_test = nn_test.fit(train_x, train_y).predict(test_x)\n",
    "print metrics.classification_report(test_y,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 10 hidden layers, and 50 epochs\n",
    "nn_1050 = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Sigmoid\", units=10),\n",
    "        Layer(\"Sigmoid\")],\n",
    "    learning_rate=0.01,\n",
    "    n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = sum(pred_list[0].tolist(),[])\n",
    "new_y = list(test_y)\n",
    "new_series = pd.Series(new)\n",
    "new_y_series = pd.Series(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0    1    2   3    4  5    6    7  8   9   All\n",
      "True                                                       \n",
      "0          295    0    0   0    1  0    0    6  0   0   302\n",
      "1            0  155   22  32    4  0    0    0  0   0   213\n",
      "2            0   17  292  11    0  0    0    3  0   0   323\n",
      "3            0    1  264   0    0  1    0    2  0   0   268\n",
      "4            0    0    0   0  278  0    0    0  0   0   278\n",
      "5          126    0    1   1    0  1    0    0  0   0   129\n",
      "6            0    0    0   0    0  0  296    0  0   0   296\n",
      "7            0    7    1   0    8  0    0  156  0   0   172\n",
      "8          182    0    0   0    0  0    0    0  8   0   190\n",
      "9            1    0    0   0    0  0    0    0  0  55    56\n",
      "All        604  180  580  44  291  2  296  167  8  55  2227\n"
     ]
    }
   ],
   "source": [
    "print pd.crosstab(new_y_series, new_series, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2227"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
