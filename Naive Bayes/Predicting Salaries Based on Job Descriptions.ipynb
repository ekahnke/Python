{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Building and testing classification models to predict salaries from the text contained in the job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import classification_report\n",
    "import csv\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a string of all descriptions (name it all_descripts):\n",
    "jobs = pd.read_csv('Train_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs=jobs[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descripts = jobs['FullDescription']\n",
    "all_descripts = \"\"\n",
    "for i in descripts:\n",
    "    all_descripts += i + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a tokenized list of substrings of only lower-case letters:\n",
    "letters_only = re.sub('[^a-zA-Z]', ' ', all_descripts)\n",
    "letters_only_lowered = letters_only.lower()\n",
    "tokenized_all_descripts = word_tokenize(letters_only_lowered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Tags for Each Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a list of pos tags:\n",
    "pos_tags = nltk.pos_tag(tokenized_all_descripts)\n",
    "pos_tags = pd.Series(pos_tags)\n",
    "pos_tags_list = []\n",
    "for i in pos_tags:\n",
    "    pos_tags_list.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN     710292\n",
       "IN     260269\n",
       "NNS    203837\n",
       "DT     194845\n",
       "JJ     191808\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 5 most common parts of speech:\n",
    "pos_tags_series = pd.Series(pos_tags_list)\n",
    "most_common_pos = pos_tags_series.value_counts()\n",
    "most_common_pos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN     0.302417\n",
       "IN     0.110813\n",
       "NNS    0.086787\n",
       "DT     0.082958\n",
       "JJ     0.081665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And their frequecies in the corpus:\n",
    "most_common_pos_freq = most_common_pos/len(tokenized_all_descripts)\n",
    "most_common_pos_freq[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental v. Theoretical Zipf's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Value counts of each token, and their rank:\n",
    "descripts_series = pd.Series(tokenized_all_descripts)\n",
    "most_common = descripts_series.value_counts()\n",
    "ranked_most_common = most_common.rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Theoretical value counts and ranks using Zipf's Law:\n",
    "s = np.random.zipf(2, len(most_common))\n",
    "s = pd.Series(s)\n",
    "theoretical_counts = s.value_counts()\n",
    "ranked_theoretical_counts = theoretical_counts.rank(ascending=False, method='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot experimental and theoretical using log-log (creates a pop-up):\n",
    "plt.scatter(np.log(ranked_most_common), np.log(most_common), color='red')\n",
    "plt.scatter(np.log(ranked_theoretical_counts), np.log(theoretical_counts))\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Theoretical(blue) v. Experimental(red)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords and Lemmatize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "no_stop_words = [i for i in tokenized_all_descripts if i not in stops]\n",
    "#stop words gone, just need to lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience    17507\n",
       "work          12382\n",
       "care          12064\n",
       "role          11848\n",
       "client        11691\n",
       "team          11139\n",
       "working       10049\n",
       "service        9624\n",
       "manager        9292\n",
       "within         9249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_list = []\n",
    "for i in no_stop_words:\n",
    "    lemmatized_list.append(lemmatizer.lemmatize(i))\n",
    "lemmatized_series = pd.Series(lemmatized_list)\n",
    "lemmatized_most_common = lemmatized_series.value_counts()\n",
    "lemmatized_most_common[:10]\n",
    "#list of 10 most common tokens after stop word removal and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience    0.007454\n",
       "work          0.005272\n",
       "care          0.005136\n",
       "role          0.005044\n",
       "client        0.004978\n",
       "team          0.004743\n",
       "working       0.004279\n",
       "service       0.004098\n",
       "manager       0.003956\n",
       "within        0.003938\n",
       "dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And their frequencies in the corpus:\n",
    "lemmatized_most_common_freq = lemmatized_most_common/len(tokenized_all_descripts)\n",
    "lemmatized_most_common_freq[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('Train_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs=jobs[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a data frame of 2 columns: (1) target (2) full descriptions\n",
    "df = pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['Id','FullDescription','SalaryNormalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salary_percentile = pd.qcut(df['SalaryNormalized'],\n",
    "                           4,\n",
    "                           labels = ['0-25', '25-50', '50-75', '75-100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['SalaryPercentile'] = salary_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['target'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df['SalaryPercentile'] == '75-100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.ix[mask, 'target'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_letters_only(string):\n",
    "    return re.sub('[^a-zA-Z]', ' ', string).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['FullDescription'] = df['FullDescription'].map(lower_letters_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[['target', 'FullDescription']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write it to a csv:\n",
    "df2.to_csv('C:/Users/Jace/Downloads/jobs_full_30000.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Split training data into 50/50 pos/neg class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_mask = df2['target'] ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3=df2[neg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.to_csv('C:/Users/Jace/Downloads/jobs_neg_class_data.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_mask = df2['target'] ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4=df2[pos_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.to_csv('C:/Users/Jace/Downloads/jobs_pos_class_data.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 2 csv's, one is all positive class, one is all negative. Now, use them to make the data and labels lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_pos = open('C:/Users/Jace/Downloads/jobs_pos_class_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_pos_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_pos_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_reader_pos = csv.reader(jobs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in csv_reader_pos:\n",
    "    jobs_pos_labels.append(int(float(line[0])))\n",
    "    jobs_pos_data.append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_pos.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_neg = open('C:/Users/Jace/Downloads/jobs_neg_class_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_neg_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_neg_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_reader_neg = csv.reader(jobs_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in csv_reader_neg:\n",
    "    jobs_neg_labels.append(int(float(line[0])))\n",
    "    jobs_neg_data.append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_neg_data = jobs_neg_data[:6918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_neg_labels = jobs_neg_labels[:6918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_neg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_data = jobs_neg_data + jobs_pos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_labels = jobs_neg_labels + jobs_pos_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "jobs_data_shuf = []\n",
    "jobs_labels_shuf = []\n",
    "index_shuf = range(len(jobs_data))\n",
    "shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    jobs_data_shuf.append(jobs_data[i])\n",
    "    jobs_labels_shuf.append(jobs_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_data = jobs_data_shuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_labels = jobs_labels_shuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create train and test sets (could have also used train-test split):\n",
    "trainset_size = int(round(len(jobs_data)*0.60))\n",
    "X_train = np.array([''.join(el) for el in jobs_data[0:trainset_size]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([el for el in jobs_labels[0:trainset_size]])\n",
    "X_test = np.array([''.join(el) for el in jobs_data[trainset_size+1:len(jobs_data)]])\n",
    "y_test = np.array([el for el in jobs_labels[trainset_size+1:len(jobs_labels)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define vectorizer and create the DTM matrices:\n",
    "vectorizer = CountVectorizer()\n",
    "dtm_train = vectorizer.fit_transform(X_train)\n",
    "dtm_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the classifier:\n",
    "nb_classifier = MultinomialNB().fit(dtm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run the classifier to predict target labels:\n",
    "y_nb_predicted = nb_classifier.predict(dtm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2156,  628],\n",
       "       [ 521, 2228]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"confusion matrix:\"\n",
    "metrics.confusion_matrix(y_test, y_nb_predicted, labels = np.unique(jobs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79233688776432321"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Classification Accuracy:'\n",
    "metrics.accuracy_score(y_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize. Then vectorize, fit and run again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we do think that lemmatization will help the classification accuracy because it will reflect the emphasis a given description may have on a certain topic (not necesarily just one unique word). In some specific cases this may actually hurt because these different (but similar) words should be treated as unique, but we think overall it should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatized_tokens(tokens, lemmatizer):\n",
    "    lemmatized = []\n",
    "    for item in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(item))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = lemmatized_tokens(tokens, lemmatizer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run vectorizer with a custom tokenizer that lemmatizes:\n",
    "lem_vectorizer = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create DTM matrices:\n",
    "dtm_train2 = lem_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_test2 = lem_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fit model:\n",
    "nb_classifier = MultinomialNB().fit(dtm_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model to predict target labels:\n",
    "y_nb_predicted = nb_classifier.predict(dtm_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78492680281944693"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy actually decreased after lemmatization. This is not what we expected. Although we did not anticipate a large increase in accuracy from lemmatization, we did anticipate some increase. Apparently the lemmatization nullified some important distinctions between similar words, whereas these distinctions were upheld in B1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Stopword removal:\n",
    "Use the original (un-lemmatized) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We anticipate that removing stopwords will increase the accuracy of the model because the stopwords likely do not help in predicting what salary level a given job description corresponds to. Therefore, keeping them in the model may lead to overfitting in some cases and thus produce the wrong classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create stopword vectorizer:\n",
    "sw_vectorizer = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the DTM matrices using the stopword vectorizer:\n",
    "dtm_train3 = sw_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_test3 = sw_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the classifier on the training DTM:\n",
    "nb_classifier = MultinomialNB().fit(dtm_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run classifier to predict target labels:\n",
    "y_nb_predicted = nb_classifier.predict(dtm_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79504789445147295"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopword removal helped a little bit here, but not by much. The accuracy improved by about .4 percent over the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens_and_pos_bigrams(string):\n",
    "    '''This function accepts a string and returns a list \n",
    "    of the pos_bigrams of tokens in the string.'''\n",
    "    \n",
    "    tokenized = word_tokenize(string)\n",
    "    pos_tuples = nltk.pos_tag(tokenized)\n",
    "    pos_tags = []\n",
    "    for (word, tag) in pos_tuples:\n",
    "        pos_tags.append(tag)\n",
    "    pos_bigrams = list(nltk.bigrams(pos_tags))\n",
    "    return tokenized + pos_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_bigram_vectorizer = CountVectorizer(tokenizer = get_tokens_and_pos_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm_train4 = pos_bigram_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_test4 = pos_bigram_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(dtm_train4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_nb_predicted = nb_classifier.predict(dtm_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869148743900235"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_nb_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Including the parts of speech bigrams did not help the accuracy of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
